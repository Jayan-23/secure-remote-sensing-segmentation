{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP35hO+DXPR1DWhdJ88fJg8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LmjxIHZoOnq_"},"outputs":[],"source":["#Imports & setup\n","import torch\n","import torch.nn.functional as F\n","import numpy as np\n","import glob\n","from PIL import Image\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","import segmentation_models_pytorch as smp\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["#Load trained base model\n","NUM_CLASSES = 5\n","\n","model = smp.Unet(\n","    encoder_name=\"resnet34\",\n","    encoder_weights=None,\n","    in_channels=3,\n","    classes=NUM_CLASSES\n",").to(device)\n","\n","model.load_state_dict(\n","    torch.load(\"models/unet_resnet34.pth\", map_location=device)\n",")\n","model.eval()\n","print(\"âœ… Base model loaded\")"],"metadata":{"id":"wzCXirn0Ouak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Dataset & validation loader\n","class MapDataset(Dataset):\n","    def __init__(self, img_dir, lbl_dir):\n","        self.img_paths = sorted(glob.glob(img_dir + \"/*.jpg\"))\n","        self.lbl_paths = sorted(glob.glob(lbl_dir + \"/*.txt\"))\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        img = Image.open(self.img_paths[idx]).convert(\"RGB\").resize((256,256))\n","        arr = np.array(img) / 255.0\n","        arr = arr.transpose(2,0,1).astype(\"float32\")\n","        label = int(open(self.lbl_paths[idx]).read().strip())\n","        return torch.tensor(arr), torch.tensor(label)"],"metadata":{"id":"Dbr17JlAOwNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["VAL_DIR = \"data/val_1\"\n","val_ds = MapDataset(f\"{VAL_DIR}/images\", f\"{VAL_DIR}/labels\")\n","val_dl = DataLoader(val_ds, batch_size=1, shuffle=False)"],"metadata":{"id":"TdgTyRyNOysL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#FGSM attack\n","def fgsm_attack(model, x, y, eps):\n","    x_adv = x.clone().detach().to(device)\n","    x_adv.requires_grad = True\n","\n","    out = model(x_adv).mean(dim=(2,3))\n","    loss = F.cross_entropy(out, y)\n","\n","    model.zero_grad()\n","    loss.backward()\n","\n","    adv = x_adv + eps * x_adv.grad.sign()\n","    adv = torch.clamp(adv, 0, 1)\n","    return adv.detach()"],"metadata":{"id":"qtBWZbmyO0mM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#FGSM evaluation\n","def eval_fgsm(model, dataloader, eps):\n","    correct, total = 0, 0\n","    for x, y in dataloader:\n","        x, y = x.to(device), y.to(device)\n","        adv = fgsm_attack(model, x, y, eps)\n","        with torch.no_grad():\n","            pred = model(adv).mean(dim=(2,3)).argmax(dim=1)\n","        correct += (pred == y).sum().item()\n","        total += 1\n","    return 100 * correct / total"],"metadata":{"id":"l61fPDBhO2Q1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#PGD attack\n","def pgd_attack(model, x, y, eps=0.04, alpha=0.005, steps=20):\n","    x_orig = x.clone().detach().to(device)\n","    x_adv = x_orig.clone()\n","\n","    for _ in range(steps):\n","        x_adv.requires_grad = True\n","        out = model(x_adv).mean(dim=(2,3))\n","        loss = F.cross_entropy(out, y)\n","        model.zero_grad()\n","        loss.backward()\n","\n","        x_adv = x_adv + alpha * x_adv.grad.sign()\n","        perturb = torch.clamp(x_adv - x_orig, -eps, eps)\n","        x_adv = torch.clamp(x_orig + perturb, 0, 1).detach()\n","\n","    return x_adv"],"metadata":{"id":"uZOoH4EdO4Ad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#PGD evaluation\n","def eval_pgd(model, dataloader, eps):\n","    correct, total = 0, 0\n","    for x, y in dataloader:\n","        x, y = x.to(device), y.to(device)\n","        adv = pgd_attack(model, x, y, eps)\n","        with torch.no_grad():\n","            pred = model(adv).mean(dim=(2,3)).argmax(dim=1)\n","        correct += (pred == y).sum().item()\n","        total += 1\n","    return 100 * correct / total"],"metadata":{"id":"VPlLE6baO59B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Run attacks\n","EPS_LIST = [0.0, 0.02, 0.04, 0.06, 0.08]\n","\n","print(\"FGSM Results\")\n","for eps in EPS_LIST:\n","    print(eps, eval_fgsm(model, val_dl, eps))\n","\n","print(\"PGD Results\")\n","for eps in EPS_LIST:\n","    print(eps, eval_pgd(model, val_dl, eps))"],"metadata":{"id":"FUuMgT0ZPEKY"},"execution_count":null,"outputs":[]}]}