{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQIxwLdX6VpU5o5SOK1Atg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bHx7XYz8K5jk"},"outputs":[],"source":["import segmentation_models_pytorch as smp\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# CONFIG\n","IMG_SIZE = 256\n","NUM_CLASSES = 5\n","EPOCHS = 25\n","BATCH_SIZE = 16\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n"],"metadata":{"id":"pakiE02NLXNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","import glob\n","from PIL import Image\n","import numpy as np\n","\n","class MapDataset(Dataset):\n","    def __init__(self, img_dir, lbl_dir):\n","        self.img_paths = sorted(glob.glob(img_dir + \"/*.jpg\"))\n","        self.lbl_paths = sorted(glob.glob(lbl_dir + \"/*.txt\"))\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        img = Image.open(self.img_paths[idx]).convert(\"RGB\")\n","        img = img.resize((IMG_SIZE, IMG_SIZE))\n","        img = np.array(img) / 255.0\n","        img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","\n","        label = int(open(self.lbl_paths[idx]).read().strip())\n","        return torch.tensor(img), torch.tensor(label)\n"],"metadata":{"id":"AN3AvjJbLH_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATASET_DIR = \"/content/drive/MyDrive/RemoteSensingProject/Dataset_Final\"\n","\n","train_ds = MapDataset(f\"{DATASET_DIR}/train/images\", f\"{DATASET_DIR}/train/labels\")\n","val_ds   = MapDataset(f\"{DATASET_DIR}/val/images\", f\"{DATASET_DIR}/val/labels\")\n","\n","train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","val_dl   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n"],"metadata":{"id":"JFfkLsnYLcqF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = smp.Unet(\n","    encoder_name=\"resnet34\",\n","    encoder_weights=\"imagenet\",\n","    in_channels=3,\n","    classes=NUM_CLASSES\n",").to(device)\n","\n","print(\"U-Net with ResNet34 initialized\")\n"],"metadata":{"id":"avM4bb-XLexR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, factor=0.5, patience=3\n",")\n"],"metadata":{"id":"J_gCjl87LgpR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_losses, val_losses = [], []\n","\n","print(\"ðŸš€ Training Started\")\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    running_loss = 0\n","\n","    for imgs, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n","        imgs, labels = imgs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(imgs)\n","        outputs = outputs.mean(dim=(2, 3))  # segmentation â†’ class\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    avg_train = running_loss / len(train_dl)\n","    train_losses.append(avg_train)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0\n","\n","    with torch.no_grad():\n","        for imgs, labels in val_dl:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","            outputs = outputs.mean(dim=(2, 3))\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","    avg_val = val_loss / len(val_dl)\n","    val_losses.append(avg_val)\n","    scheduler.step(avg_val)\n","\n","    print(f\"Epoch {epoch+1} | Train: {avg_train:.4f} | Val: {avg_val:.4f}\")\n"],"metadata":{"id":"kc8C_dGfLiVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(7,5))\n","plt.plot(train_losses, label=\"Train Loss\")\n","plt.plot(val_losses, label=\"Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training vs Validation Loss\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"CJel0ILqLko9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.makedirs(\"models\", exist_ok=True)\n","\n","MODEL_PATH = \"models/unet_resnet34.pth\"\n","torch.save(model.state_dict(), MODEL_PATH)\n","\n","print(f\"âœ… Model saved at {MODEL_PATH}\")\n"],"metadata":{"id":"21EYiAdrLmIy"},"execution_count":null,"outputs":[]}]}