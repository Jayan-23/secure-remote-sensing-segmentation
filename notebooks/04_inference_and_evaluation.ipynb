{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPN75RmY57rb4x4qsNUZNFK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"v28_wT3YLyGB"},"outputs":[],"source":["import torch\n","import segmentation_models_pytorch as smp\n","import numpy as np\n","from PIL import Image\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["# CONFIG\n","IMG_SIZE = 256\n","NUM_CLASSES = 5\n","CLASS_NAMES = [\"LULC\", \"River\", \"Road\", \"Settlement\", \"Soil\"]\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"],"metadata":{"id":"W3uA2NaZL3Cb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","\n","class MapDataset(torch.utils.data.Dataset):\n","    def __init__(self, img_dir, lbl_dir):\n","        self.img_paths = sorted(glob.glob(img_dir + \"/*.jpg\"))\n","        self.lbl_paths = sorted(glob.glob(lbl_dir + \"/*.txt\"))\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        img = Image.open(self.img_paths[idx]).convert(\"RGB\")\n","        img = img.resize((IMG_SIZE, IMG_SIZE))\n","        img = np.array(img) / 255.0\n","        img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","\n","        label = int(open(self.lbl_paths[idx]).read().strip())\n","        return torch.tensor(img), torch.tensor(label)"],"metadata":{"id":"K37CC1UvL43c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATASET_DIR = \"/content/drive/MyDrive/RemoteSensingProject/Dataset_Final\"\n","\n","val_ds = MapDataset(\n","    f\"{DATASET_DIR}/val/images\",\n","    f\"{DATASET_DIR}/val/labels\"\n",")\n","\n","val_dl = DataLoader(val_ds, batch_size=16, shuffle=False)\n","print(\"Validation samples:\", len(val_ds))"],"metadata":{"id":"BRujoF5yL9A7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = smp.Unet(\n","    encoder_name=\"resnet34\",\n","    encoder_weights=None,\n","    in_channels=3,\n","    classes=NUM_CLASSES\n",").to(device)\n","\n","MODEL_PATH = \"models/unet_resnet34.pth\"\n","model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n","model.eval()\n","\n","print(\"âœ… Model loaded successfully\")"],"metadata":{"id":"mT4LKcGGL91I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_image(img_path):\n","    img = Image.open(img_path).convert(\"RGB\")\n","    img = img.resize((IMG_SIZE, IMG_SIZE))\n","    arr = np.array(img) / 255.0\n","    tensor = torch.tensor(\n","        arr.transpose(2, 0, 1),\n","        dtype=torch.float32\n","    ).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        out = model(tensor)\n","        out = out.mean(dim=(2, 3))\n","        probs = torch.softmax(out, dim=1)[0].cpu().numpy()\n","\n","    cls = np.argmax(probs)\n","    conf = probs[cls] * 100\n","\n","    print(f\"Predicted Class : {CLASS_NAMES[cls]}\")\n","    print(f\"Confidence      : {conf:.2f}%\")"],"metadata":{"id":"6V0jOzS6MA6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for imgs, lbls in val_dl:\n","        imgs, lbls = imgs.to(device), lbls.to(device)\n","        out = model(imgs)\n","        out = out.mean(dim=(2, 3))\n","        preds = torch.argmax(out, dim=1)\n","\n","        correct += (preds == lbls).sum().item()\n","        total += lbls.size(0)\n","\n","accuracy = correct / total\n","print(f\"ðŸ“Œ Validation Accuracy: {accuracy*100:.2f}%\")"],"metadata":{"id":"jQZDWUtcMDee"},"execution_count":null,"outputs":[]}]}